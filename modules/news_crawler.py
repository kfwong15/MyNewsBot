import requests
from bs4 import BeautifulSoup
import random
import logging
from datetime import datetime
import re
import sqlite3
import os
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('news_crawler')

# æ–°é—»åˆ†ç±»URL - å·²æ›´æ–°å¹¶éªŒè¯
NEWS_CATEGORIES = {
    'latest': 'https://www.thestar.com.my/news',
    'nation': 'https://www.thestar.com.my/news/nation',
    'politics': 'https://www.thestar.com.my/news/politics',
    'business': 'https://www.thestar.com.my/business',
    'sport': 'https://www.thestar.com.my/sport',
    'entertainment': 'https://www.thestar.com.my/entertainment',
    'tech': 'https://www.thestar.com.my/tech',
    'lifestyle': 'https://www.thestar.com.my/lifestyle'
}

# å¤šä¸ªç”¨æˆ·ä»£ç†è½®æ¢ä½¿ç”¨
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:126.0) Gecko/20100101 Firefox/126.0',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
    'Mozilla/5.0 (iPhone; CPU iPhone OS 17_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1'
]

class NewsDatabase:
    def __init__(self, db_path='news.db'):
        self.conn = sqlite3.connect(db_path)
        self._create_table()
    
    def _create_table(self):
        self.conn.execute('''CREATE TABLE IF NOT EXISTS sent_news
                           (link TEXT PRIMARY KEY, sent_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')
        self.conn.commit()
    
    def is_duplicate(self, link):
        """æ£€æŸ¥é“¾æ¥æ˜¯å¦å·²å‘é€è¿‡"""
        cursor = self.conn.execute("SELECT 1 FROM sent_news WHERE link=?", (link,))
        return cursor.fetchone() is not None
    
    def mark_as_sent(self, link):
        """æ ‡è®°é“¾æ¥ä¸ºå·²å‘é€"""
        try:
            self.conn.execute("INSERT OR IGNORE INTO sent_news (link) VALUES (?)", (link,))
            self.conn.commit()
        except sqlite3.IntegrityError:
            pass  # å¿½ç•¥é‡å¤æ’å…¥
    
    def cleanup_old_entries(self, days=7):
        """ç§»é™¤è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ¡ç›®"""
        self.conn.execute("DELETE FROM sent_news WHERE sent_time < datetime('now', ?)", (f'-{days} days',))
        self.conn.commit()
        logger.info(f"æ¸…ç†äº† {self.conn.total_changes} æ¡æ—§è®°å½•")

def get_random_user_agent():
    """è·å–éšæœºç”¨æˆ·ä»£ç†"""
    return random.choice(USER_AGENTS)

def create_session():
    """åˆ›å»ºå¸¦æœ‰éšæœºç”¨æˆ·ä»£ç†çš„ä¼šè¯"""
    session = requests.Session()
    user_agent = get_random_user_agent()
    session.headers.update({
        'User-Agent': user_agent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Referer': 'https://www.thestar.com.my/',
    })
    logger.info(f"ä½¿ç”¨ç”¨æˆ·ä»£ç†: {user_agent[:60]}...")
    return session

def get_proxy():
    """ä»ç¯å¢ƒå˜é‡è·å–ä»£ç†è®¾ç½®"""
    proxy_url = os.getenv('PROXY_URL')
    if proxy_url:
        return {
            'http': proxy_url,
            'https': proxy_url
        }
    return None

def check_website_health(session):
    """æ£€æŸ¥TheStarç½‘ç«™æ˜¯å¦å¯ç”¨"""
    try:
        logger.info("æ£€æŸ¥ç½‘ç«™å¥åº·çŠ¶å†µ...")
        response = session.get('https://www.thestar.com.my', timeout=10)
        
        if response.status_code == 200:
            logger.info("ç½‘ç«™çŠ¶æ€æ­£å¸¸")
            return True
        else:
            logger.warning(f"ç½‘ç«™è¿”å›é200çŠ¶æ€ç : {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"ç½‘ç«™å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False

def fetch_category_news(session, category, url, db):
    """æŠ“å–å•ä¸ªåˆ†ç±»çš„æ–°é—»"""
    logger.info(f"å¼€å§‹æŠ“å–åˆ†ç±»: {category} ({url})")
    news_items = []
    
    try:
        # è®¾ç½®ä»£ç†
        proxies = get_proxy()
        
        # å‘é€è¯·æ±‚
        response = session.get(url, timeout=15, proxies=proxies)
        logger.info(f"å“åº”çŠ¶æ€: {response.status_code}")
        
        # å¤„ç†é‡å®šå‘
        if response.history:
            logger.info(f"è¯·æ±‚è¢«é‡å®šå‘è‡³: {response.url}")
        
        # æ£€æŸ¥çŠ¶æ€ç 
        response.raise_for_status()
        
        # è§£æHTML
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨
        possible_selectors = [
            'div.timeline-item',
            'article.card',
            '.story-list .story',
            '.news-list .item',
            '.headline-list .item',
            'div.article'
        ]
        
        articles = None
        for selector in possible_selectors:
            articles = soup.select(selector)
            if articles:
                logger.info(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
                articles = articles[:20]  # æ¯ç±»æœ€å¤š20æ¡
                break
        
        # å¤‡ç”¨è§£æç­–ç•¥
        if not articles:
            logger.warning(f"æœªæ‰¾åˆ°æ–‡ç« å®¹å™¨ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
            
            # å°è¯•æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ–°é—»é“¾æ¥çš„å…ƒç´ 
            news_links = soup.select('a[href*="/news/"]')
            if news_links:
                logger.info(f"æ‰¾åˆ° {len(news_links)} ä¸ªæ–°é—»é“¾æ¥")
                # è·å–é“¾æ¥çš„çˆ¶å®¹å™¨ä½œä¸ºæ–‡ç« å…ƒç´ 
                articles = [link.find_parent('div') for link in news_links]
                articles = [a for a in articles if a is not None][:20]
        
        if not articles:
            logger.warning(f"åˆ†ç±» {category} æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ")
            return []
        
        # è§£ææ¯ç¯‡æ–‡ç« 
        for article in articles:
            try:
                # å°è¯•å¤šç§é€‰æ‹©å™¨æ‰¾åˆ°æ ‡é¢˜
                title_elem = article.select_one('h2 a, h3 a, .headline a, .title a, a.headline')
                if not title_elem:
                    continue
                
                title = title_elem.get_text(strip=True)
                link = title_elem.get('href', '')
                
                # å¤„ç†ç›¸å¯¹URL
                if link and not link.startswith('http'):
                    if link.startswith('//'):
                        link = f'https:{link}'
                    else:
                        link = f'https://www.thestar.com.my{link}'
                
                # è·³è¿‡é‡å¤
                if db.is_duplicate(link):
                    continue
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨æ‰¾åˆ°å›¾ç‰‡
                img_elem = article.select_one('img, .image img, .thumbnail img')
                img_url = img_elem.get('src', '') if img_elem else ''
                if img_url and img_url.startswith('//'):
                    img_url = f'https:{img_url}'
                elif img_url and img_url.startswith('/'):
                    img_url = f'https://www.thestar.com.my{img_url}'
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨æ‰¾åˆ°æ‘˜è¦
                summary_elem = article.select_one('p, .summary, .description, .excerpt')
                summary = summary_elem.get_text(strip=True) if summary_elem else ""
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨æ‰¾åˆ°æ—¶é—´
                time_elem = article.select_one('div.timestamp, time, .date, .publish-date')
                time_str = time_elem.get_text(strip=True) if time_elem else datetime.now().strftime('%Y-%m-%d')
                
                # æ¸…ç†æ—¶é—´æ ¼å¼
                time_str = re.sub(r'\s+', ' ', time_str)
                
                # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                news_items.append({
                    'title': title,
                    'link': link,
                    'img_url': img_url,
                    'summary': summary,
                    'time': time_str,
                    'category': category
                })
                
                # æ ‡è®°ä¸ºå·²å‘é€
                db.mark_as_sent(link)
                
            except Exception as e:
                logger.error(f"è§£ææ–‡ç« å¤±è´¥: {e}", exc_info=True)
        
        logger.info(f"æˆåŠŸæŠ“å– {len(news_items)} æ¡ {category} æ–°é—»")
        return news_items
    
    except requests.exceptions.HTTPError as e:
        status_code = e.response.status_code if e.response else "æœªçŸ¥"
        logger.error(f"HTTPé”™è¯¯ ({status_code}): {e}")
        
        # å¯¹äºæ”¿æ²»åˆ†ç±»ä½¿ç”¨å¤‡ç”¨URL
        if status_code == 404 and "politics" in category:
            logger.warning("å°è¯•ä½¿ç”¨æ”¿æ²»åˆ†ç±»å¤‡ç”¨URL")
            return fetch_category_news(session, category, "https://www.thestar.com.my/news/nation/politics", db)
        
        return []
    
    except Exception as e:
        logger.error(f"æŠ“å–åˆ†ç±» {category} å¤±è´¥: {e}", exc_info=True)
        return []

def fetch_news():
    """ä»TheStaræŠ“å–æ–°é—»"""
    db = NewsDatabase()
    all_news = []
    
    # åˆ›å»ºä¼šè¯
    session = create_session()
    
    # é¦–å…ˆè®¿é—®ä¸»é¡µè·å–å¿…è¦çš„ cookies
    try:
        logger.info("è®¿é—®ä¸»é¡µè·å– cookies...")
        homepage_response = session.get('https://www.thestar.com.my', timeout=15)
        homepage_response.raise_for_status()
    except Exception as e:
        logger.warning(f"è·å–ä¸»é¡µ cookies å¤±è´¥: {e}")
    
    # æ£€æŸ¥ç½‘ç«™å¥åº·çŠ¶æ€
    if not check_website_health(session):
        logger.error("ç½‘ç«™ä¸å¯ç”¨ï¼Œè·³è¿‡æŠ“å–")
        return []
    
    # éå†æ‰€æœ‰åˆ†ç±»
    for category, url in NEWS_CATEGORIES.items():
        max_retries = 2
        retry_count = 0
        category_news = []
        
        while retry_count < max_retries and not category_news:
            category_news = fetch_category_news(session, category, url, db)
            retry_count += 1
            
            if not category_news and retry_count < max_retries:
                wait_time = 3
                logger.info(f"{wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        all_news.extend(category_news)
    
    # æ¸…ç†æ—§æ¡ç›®
    db.cleanup_old_entries()
    
    logger.info(f"æ€»å…±æŠ“å–åˆ° {len(all_news)} æ¡æ–°é—»")
    return all_news

def select_random_news(news_list, min_news=30, max_news=50):
    """éšæœºé€‰æ‹©æŒ‡å®šæ•°é‡çš„æ–°é—»"""
    if not news_list:
        logger.warning("æ–°é—»åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•é€‰æ‹©")
        return []
    
    num_news = random.randint(min_news, min(max_news, len(news_list)))
    selected = random.sample(news_list, num_news)
    logger.info(f"ä» {len(news_list)} æ¡æ–°é—»ä¸­éšæœºé€‰æ‹©äº† {num_news} æ¡")
    return selected

def format_news_message(news):
    """æ ¼å¼åŒ–æ–°é—»ä¸ºTelegramæ¶ˆæ¯"""
    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦ä»¥é¿å…Markdownè§£æé—®é¢˜
    def escape_markdown(text):
        for char in ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']:
            text = text.replace(char, f'\\{char}')
        return text
    
    title = escape_markdown(news['title'])
    summary = escape_markdown(news['summary'])
    
    return (
        f"ğŸ”¹ *{title}*\n"
        f"â° {news['time']}\n"
        f"{summary}\n"
        f"[é˜…è¯»å…¨æ–‡]({news['link']})"
    )

if __name__ == "__main__":
    # æµ‹è¯•çˆ¬è™«
    print("=" * 50)
    print("å¼€å§‹æµ‹è¯•æ–°é—»çˆ¬è™«")
    print("=" * 50)
    
    news = fetch_news()
    print(f"\næŠ“å–åˆ° {len(news)} æ¡æ–°é—»")
    
    if news:
        print("\nå‰3æ¡æ–°é—»ç¤ºä¾‹:")
        for i, item in enumerate(news[:3], 1):
            print(f"\n--- æ–°é—» {i} ---")
            print(f"æ ‡é¢˜: {item['title']}")
            print(f"åˆ†ç±»: {item['category']}")
            print(f"é“¾æ¥: {item['link']}")
            print(f"å›¾ç‰‡: {item['img_url']}")
            print(f"æ‘˜è¦: {item['summary']}")
            print(f"æ—¶é—´: {item['time']}")
        
        # æµ‹è¯•éšæœºé€‰æ‹©
        selected = select_random_news(news)
        print(f"\néšæœºé€‰æ‹© {len(selected)} æ¡æ–°é—»")
        
        # æµ‹è¯•æ¶ˆæ¯æ ¼å¼åŒ–
        print("\næ ¼å¼åŒ–æ¶ˆæ¯ç¤ºä¾‹:")
        print(format_news_message(news[0]))
    else:
        print("æœªæŠ“å–åˆ°ä»»ä½•æ–°é—»")
