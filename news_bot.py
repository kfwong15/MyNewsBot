import os
import time
import re
import sys
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import requests
from bs4 import BeautifulSoup
import random

# ====== é…ç½® ======
# ä»ç¯å¢ƒå˜é‡è·å– Telegram ä¿¡æ¯
TG_BOT_TOKEN = os.environ.get("TG_BOT_TOKEN")
TG_CHAT_ID = os.environ.get("TG_CHAT_ID")

# éªŒè¯ç¯å¢ƒå˜é‡æ˜¯å¦è®¾ç½®
if not TG_BOT_TOKEN or not TG_CHAT_ID:
    print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½® TG_BOT_TOKEN å’Œ TG_CHAT_ID ç¯å¢ƒå˜é‡")
    sys.exit(1)

API_URL = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage"

# âœ… è®¾ç½® Selenium æµè§ˆå™¨
def setup_browser():
    try:
        # é…ç½® Chrome é€‰é¡¹
        chrome_options = Options()
        chrome_options.add_argument("--headless")  # æ— å¤´æ¨¡å¼
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36")
        
        # ç§»é™¤è‡ªåŠ¨åŒ–ç‰¹å¾
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # è®¾ç½® WebDriver
        service = Service(executable_path='/usr/bin/chromedriver')
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        # æ‰§è¡Œ JavaScript æ¥éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        return driver
    except Exception as e:
        print(f"âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None

# âœ… ä½¿ç”¨æµè§ˆå™¨æŠ“å–é¡µé¢
def fetch_with_browser(url, driver):
    try:
        # æ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸º
        driver.get(url)
        
        # éšæœºæ»šåŠ¨é¡µé¢
        for _ in range(random.randint(2, 5)):
            scroll_height = random.randint(300, 1000)
            driver.execute_script(f"window.scrollBy(0, {scroll_height});")
            time.sleep(random.uniform(0.5, 2.0))
        
        # éšæœºç§»åŠ¨é¼ æ ‡
        action = webdriver.ActionChains(driver)
        action.move_by_offset(random.randint(10, 100), random.randint(10, 100)).perform()
        time.sleep(random.uniform(0.3, 1.5))
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # è·å–é¡µé¢æºç 
        page_source = driver.page_source
        return page_source
    except Exception as e:
        print(f"âŒ æµè§ˆå™¨æŠ“å–å¤±è´¥: {str(e)}")
        return None

# âœ… ä¸­å›½æŠ¥æ–°é—»æŠ“å–
def fetch_chinapress(driver):
    try:
        url = "https://www.chinapress.com.my/"
        page_source = fetch_with_browser(url, driver)
        
        if not page_source:
            return ["âŒ ä¸­å›½æŠ¥æŠ“å–å¤±è´¥ï¼šæ— æ³•è·å–ç½‘é¡µå†…å®¹"]
        
        soup = BeautifulSoup(page_source, 'html.parser')
        news_items = []
        
        # æŸ¥æ‰¾å¤´æ¡æ–°é—»
        top_news = soup.select_one('div.top-story')
        if top_news:
            title_tag = top_news.find('h1', class_='post-title')
            if title_tag and title_tag.a:
                title = title_tag.get_text(strip=True)
                link = title_tag.a['href']
                news_items.append(f"ğŸ“° <b>ä¸­å›½æŠ¥å¤´æ¡</b>\nğŸ“Œ {title}\nğŸ”— {link}")
        
        # æŸ¥æ‰¾å…¶ä»–æ–°é—»
        for article in soup.select('div.post-box:not(.top-story)'):
            if len(news_items) >= 3:  # æœ€å¤š3æ¡
                break
                
            title_tag = article.find('h3', class_='post-title')
            if title_tag and title_tag.a:
                title = title_tag.get_text(strip=True)
                link = title_tag.a['href']
                news_items.append(f"ğŸ“° <b>ä¸­å›½æŠ¥</b>\nğŸ“Œ {title}\nğŸ”— {link}")
                
        return news_items if news_items else ["âŒ ä¸­å›½æŠ¥æŠ“å–å¤±è´¥ï¼šæœªæ‰¾åˆ°æ–°é—»å†…å®¹"]
        
    except Exception as e:
        return [f"âŒ ä¸­å›½æŠ¥æŠ“å–å¤±è´¥ï¼š{str(e)}"]

# âœ… ä¸œæ–¹æ—¥æŠ¥æ–°é—»æŠ“å–
def fetch_oriental(driver):
    try:
        url = "https://www.orientaldaily.com.my"
        page_source = fetch_with_browser(url, driver)
        
        if not page_source:
            # å°è¯•å¤‡ç”¨RSSæº
            rss_url = "https://www.orientaldaily.com.my/rss"
            response = requests.get(rss_url, timeout=10)
            if response.status_code == 200:
                return parse_rss(response.text, "ä¸œæ–¹æ—¥æŠ¥")
            else:
                return ["âŒ ä¸œæ–¹æ—¥æŠ¥æŠ“å–å¤±è´¥ï¼šæ— æ³•è·å–ç½‘é¡µå†…å®¹"]
        
        soup = BeautifulSoup(page_source, 'html.parser')
        news_items = []
        
        # æŸ¥æ‰¾å¤´æ¡æ–°é—»
        top_news = soup.select_one('div.top-news')
        if top_news:
            title_tag = top_news.find('h1')
            if title_tag and title_tag.a:
                title = title_tag.get_text(strip=True)
                link = title_tag.a['href']
                if not link.startswith('http'):
                    link = f"https://www.orientaldaily.com.my{link}"
                news_items.append(f"ğŸ“° <b>ä¸œæ–¹æ—¥æŠ¥å¤´æ¡</b>\nğŸ“Œ {title}\nğŸ”— {link}")
        
        # æŸ¥æ‰¾å…¶ä»–æ–°é—»
        for article in soup.select('div.news-list'):
            if len(news_items) >= 3:  # æœ€å¤š3æ¡
                break
                
            title_tag = article.find('h2')
            if title_tag and title_tag.a:
                title = title_tag.get_text(strip=True)
                link = title_tag.a['href']
                if not link.startswith('http'):
                    link = f"https://www.orientaldaily.com.my{link}"
                news_items.append(f"ğŸ“° <b>ä¸œæ–¹æ—¥æŠ¥</b>\nğŸ“Œ {title}\nğŸ”— {link}")
                
        return news_items if news_items else ["âŒ ä¸œæ–¹æ—¥æŠ¥æŠ“å–å¤±è´¥ï¼šæœªæ‰¾åˆ°æ–°é—»å†…å®¹"]
        
    except Exception as e:
        return [f"âŒ ä¸œæ–¹æ—¥æŠ¥æŠ“å–å¤±è´¥ï¼š{str(e)}"]

# âœ… RSSè§£æå¤‡ç”¨æ–¹æ¡ˆ
def parse_rss(xml_content, source_name):
    try:
        from xml.etree import ElementTree as ET
        
        root = ET.fromstring(xml_content)
        news_items = []
        
        # è§£æRSS/XML
        for item in root.findall('.//item'):
            if len(news_items) >= 3:  # æœ€å¤š3æ¡
                break
                
            title = item.findtext('title', '').strip()
            link = item.findtext('link', '').strip()
            
            if title and link:
                news_items.append(f"ğŸ“° <b>{source_name}</b>\nğŸ“Œ {title}\nğŸ”— {link}")
        
        return news_items if news_items else [f"âŒ {source_name} RSSè§£æå¤±è´¥ï¼šæ— æœ‰æ•ˆå†…å®¹"]
    
    except Exception as e:
        return [f"âŒ {source_name} RSSè§£æå¤±è´¥ï¼š{str(e)}"]

# âœ… Telegramæ¶ˆæ¯å‘é€
def send_telegram(message):
    try:
        # æ¸…ç†æ¶ˆæ¯ä¸­çš„æ— æ•ˆå­—ç¬¦
        clean_msg = re.sub(r'[^\x20-\x7E\u4E00-\u9FFF]', '', message)
        
        payload = {
            "chat_id": TG_CHAT_ID,
            "text": clean_msg,
            "parse_mode": "HTML",
            "disable_web_page_preview": True
        }
        
        response = requests.post(API_URL, json=payload, timeout=25)
        response.raise_for_status()
        
        print(f"âœ… æ¶ˆæ¯å‘é€æˆåŠŸ: {clean_msg[:50]}...")
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Telegram APIè¯·æ±‚å¤±è´¥: {str(e)}")
        return False
    except Exception as e:
        print(f"âŒ å‘é€æ¶ˆæ¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
        return False

# âœ… ä¸»å‡½æ•°
def main():
    print("="*50)
    print("å¼€å§‹æ–°é—»æ¨é€ä»»åŠ¡")
    print("="*50)
    
    # åˆå§‹åŒ–æµè§ˆå™¨
    print("\nåˆå§‹åŒ–æµè§ˆå™¨...")
    driver = setup_browser()
    if not driver:
        print("âŒ æ— æ³•åˆå§‹åŒ–æµè§ˆå™¨ï¼Œé€€å‡ºç¨‹åº")
        sys.exit(1)
    
    try:
        # è·å–æ–°é—»
        print("\næŠ“å–ä¸­å›½æŠ¥æ–°é—»...")
        chinapress_news = fetch_chinapress(driver)
        print(f"æ‰¾åˆ° {len([n for n in chinapress_news if 'âŒ' not in n])} æ¡ä¸­å›½æŠ¥æ–°é—»")
        
        print("\næŠ“å–ä¸œæ–¹æ—¥æŠ¥æ–°é—»...")
        oriental_news = fetch_oriental(driver)
        print(f"æ‰¾åˆ° {len([n for n in oriental_news if 'âŒ' not in n])} æ¡ä¸œæ–¹æ—¥æŠ¥æ–°é—»")
        
        all_news = chinapress_news + oriental_news
        
        # å‘é€æ–°é—»
        success_count = 0
        for news in all_news:
            if "âŒ" not in news:  # åªå‘é€æˆåŠŸæŠ“å–çš„æ–°é—»
                max_retries = 3
                for attempt in range(max_retries):
                    if send_telegram(news):
                        success_count += 1
                        time.sleep(random.uniform(1, 3))  # éšæœºæ¶ˆæ¯é—´éš”
                        break
                    elif attempt < max_retries - 1:
                        wait_time = 3 + attempt * 2
                        print(f"ç­‰å¾…{wait_time}ç§’åé‡è¯• ({attempt+1}/{max_retries})...")
                        time.sleep(wait_time)
        
        print("\n" + "="*50)
        print(f"æ–°é—»æ¨é€å®Œæˆ! æˆåŠŸå‘é€ {success_count}/{len(all_news)} æ¡æ–°é—»")
        print("="*50)
        
        # å¦‚æœæœ‰ä»»ä½•å¤±è´¥ï¼Œéé›¶é€€å‡ºç 
        if success_count < len(all_news):
            sys.exit(1)
            
    finally:
        # ç¡®ä¿æµè§ˆå™¨å…³é—­
        driver.quit()
        print("\næµè§ˆå™¨å·²å…³é—­")

if __name__ == "__main__":
    main()
