import os
import requests
import time
import sys
import random
import json
from datetime import datetime
from bs4 import BeautifulSoup

# ====== é…ç½® ======
TG_BOT_TOKEN = os.environ.get("TG_BOT_TOKEN")
TG_CHAT_ID = os.environ.get("TG_CHAT_ID")

if not TG_BOT_TOKEN or not TG_CHAT_ID:
    print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®TG_BOT_TOKENå’ŒTG_CHAT_IDç¯å¢ƒå˜é‡")
    sys.exit(1)

API_URL = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage"

# Googleæ–°é—»API URL (æ›´å¯é çš„æ–¹æ³•)
GOOGLE_NEWS_API_URL = "https://news.google.com/rss?hl=en-MY&gl=MY&ceid=MY:en"

# ç›´æ¥è§£ææ›¿ä»£æ–¹æ¡ˆ
NEWS_SOURCES = {
    "MalaysiaKini": "https://www.malaysiakini.com/news",
    "The Star": "https://www.thestar.com.my/news",
    "New Straits Times": "https://www.nst.com.my/news",
    "Malay Mail": "https://www.malaymail.com/news/malaysia",
    "Free Malaysia Today": "https://www.freemalaysiatoday.com/category/nation/"
}

# è¯·æ±‚å¤´åˆ—è¡¨
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Safari/605.1.15",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1",
    "Mozilla/5.0 (Linux; Android 13; SM-S908B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"
]

def get_headers():
    return {
        "User-Agent": random.choice(USER_AGENTS),
        "Accept-Language": "en-US,en;q=0.5",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Connection": "keep-alive"
    }

def fetch_google_news_api(max_news=50):
    """ä½¿ç”¨Google RSS APIè·å–æ–°é—»"""
    try:
        print("ğŸ” ä½¿ç”¨Google RSS APIè·å–æ–°é—»...")
        response = requests.get(GOOGLE_NEWS_API_URL, headers=get_headers(), timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'xml')  # æ³¨æ„ä½¿ç”¨xmlè§£æå™¨
        items = soup.find_all('item')[:max_news]
        
        news_items = []
        for item in items:
            title = item.title.text if item.title else "æ— æ ‡é¢˜"
            link = item.link.text if item.link else "#"
            pub_date = item.pubDate.text if item.pubDate else ""
            source = item.source.text if item.source else "æœªçŸ¥æ¥æº"
            
            news_item = f"ğŸ“° <b>{title}</b>\n" \
                       f"ğŸ·ï¸ æ¥æº: {source}\n" \
                       f"â° æ—¶é—´: {pub_date}\n" \
                       f"ğŸ”— {link}"
            news_items.append(news_item)
        
        return news_items
    
    except Exception as e:
        print(f"âŒ Google RSS APIè¯·æ±‚å¤±è´¥: {str(e)}")
        return []

def fetch_direct_news_sources(max_news=50):
    """ç›´æ¥æŠ“å–é©¬æ¥è¥¿äºšæ–°é—»ç½‘ç«™"""
    print("ğŸ” ç›´æ¥æŠ“å–é©¬æ¥è¥¿äºšæ–°é—»ç½‘ç«™...")
    all_news = []
    sources = list(NEWS_SOURCES.items())
    random.shuffle(sources)  # éšæœºæ‰“ä¹±é¡ºåº
    
    for source_name, url in sources:
        if len(all_news) >= max_news:
            break
            
        try:
            print(f"â³ æŠ“å– {source_name}...")
            response = requests.get(url, headers=get_headers(), timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = []
            
            # é’ˆå¯¹ä¸åŒç½‘ç«™ä½¿ç”¨ä¸åŒçš„é€‰æ‹©å™¨
            if source_name == "MalaysiaKini":
                articles = soup.select('h3.title')[:10]  # å–å‰10æ¡
            elif source_name == "The Star":
                articles = soup.select('div.story-card a')[:10]
            elif source_name == "New Straits Times":
                articles = soup.select('h5.card-title a')[:10]
            elif source_name == "Malay Mail":
                articles = soup.select('h4.card-title a')[:10]
            elif source_name == "Free Malaysia Today":
                articles = soup.select('h3.entry-title a')[:10]
            
            for article in articles:
                if len(all_news) >= max_news:
                    break
                    
                title = article.get_text(strip=True)
                link = article.get('href', '')
                
                # ç¡®ä¿é“¾æ¥å®Œæ•´
                if link and not link.startswith('http'):
                    if source_name == "The Star":
                        link = f"https://www.thestar.com.my{link}"
                    elif source_name == "New Straits Times":
                        link = f"https://www.nst.com.my{link}"
                
                if title and link:
                    news_item = f"ğŸ“° <b>{title}</b>\n" \
                               f"ğŸ·ï¸ æ¥æº: {source_name}\n" \
                               f"ğŸ”— {link}"
                    all_news.append(news_item)
            
            time.sleep(random.uniform(1, 2))  # ç½‘ç«™é—´å»¶è¿Ÿ
            
        except Exception as e:
            print(f"âš ï¸ {source_name} æŠ“å–å¤±è´¥: {str(e)}")
    
    return all_news

def fetch_news(max_news=50):
    """ä¸»æŠ“å–å‡½æ•°ï¼Œå°è¯•å¤šç§æ–¹æ³•"""
    print(f"ğŸ¯ ç›®æ ‡æŠ“å– {max_news} æ¡æ–°é—»")
    
    # é¦–å…ˆå°è¯•Google RSS API
    news_items = fetch_google_news_api(max_news)
    
    # å¦‚æœAPIæ–¹æ³•å¤±è´¥æˆ–æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨ç›´æ¥æŠ“å–
    if len(news_items) < max_news:
        needed = max_news - len(news_items)
        direct_news = fetch_direct_news_sources(needed)
        news_items.extend(direct_news)
    
    # å¦‚æœä»ç„¶æ²¡æœ‰è¶³å¤Ÿæ–°é—»ï¼Œæ·»åŠ å¤‡ç”¨æ–°é—»
    if not news_items:
        print("âš ï¸ æ‰€æœ‰æ–¹æ³•å‡å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–°é—»")
        news_items = [
            "ğŸ“¢ ä»Šæ—¥æ–°é—»æŠ“å–é‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•",
            "ğŸ“° <b>é©¬æ¥è¥¿äºšæœ€æ–°æ–°é—»</b>\nğŸ·ï¸ æ¥æº: ç³»ç»Ÿé€šçŸ¥\nğŸ”— https://www.thestar.com.my",
            "ğŸ“° <b>æŸ¥çœ‹é©¬æ¥è¥¿äºšæ–°é—»</b>\nğŸ·ï¸ æ¥æº: ç³»ç»Ÿé€šçŸ¥\nğŸ”— https://www.nst.com.my"
        ]
    
    return news_items[:max_news]

def send_telegram(message):
    try:
        payload = {
            "chat_id": TG_CHAT_ID,
            "text": message,
            "parse_mode": "HTML",
            "disable_web_page_preview": False
        }
        
        response = requests.post(API_URL, json=payload, timeout=25)
        response.raise_for_status()
        return True
    except Exception as e:
        print(f"âŒ å‘é€å¤±è´¥: {str(e)}")
        return False

def main():
    print("="*50)
    start_time = datetime.now()
    print(f"ğŸ“… é©¬æ¥è¥¿äºšæ–°é—»æ¨é€ä»»åŠ¡å¼€å§‹ {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*50)
    
    # è·å–30-50æ¡æ–°é—»
    target_count = random.randint(30, 50)
    news_items = fetch_news(target_count)
    
    print(f"\nğŸ“Š å…±æ‰¾åˆ° {len(news_items)} æ¡æ–°é—»ï¼Œå‡†å¤‡å‘é€...")
    
    success_count = 0
    for index, news in enumerate(news_items, 1):
        if send_telegram(news):
            success_count += 1
            print(f"âœ… å·²å‘é€ {index}/{len(news_items)}")
            
            # éšæœºå»¶è¿Ÿï¼Œé¿å…å‘é€è¿‡å¿«
            delay = random.uniform(0.5, 2.0)
            time.sleep(delay)
        else:
            print(f"âš ï¸ å‘é€å¤±è´¥ {index}/{len(news_items)}")
    
    end_time = datetime.now()
    duration = end_time - start_time
    
    print("\n" + "="*50)
    print(f"ğŸ ä»»åŠ¡å®Œæˆ! æˆåŠŸå‘é€ {success_count}/{len(news_items)} æ¡æ–°é—»")
    print(f"â±ï¸ æ€»è€—æ—¶: {duration.total_seconds():.1f}ç§’")
    print("="*50)
    
    # ç”ŸæˆæŠ¥å‘Šæ¶ˆæ¯
    report = f"ğŸ“Š æ–°é—»æ¨é€æŠ¥å‘Š\n" \
             f"â° å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n" \
             f"â° ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n" \
             f"â±ï¸ æ€»è€—æ—¶: {duration.total_seconds():.1f}ç§’\n" \
             f"ğŸ“° ç›®æ ‡æ•°é‡: {target_count}\n" \
             f"âœ… æˆåŠŸå‘é€: {success_count}"
    
    send_telegram(report)
    
    if success_count < len(news_items):
        sys.exit(1)

if __name__ == "__main__":
    main()
